{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d54c920",
   "metadata": {},
   "source": [
    "### building chatbot with multiple tools "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d4a9f",
   "metadata": {},
   "source": [
    "## simple bs4 web scraping tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tavily Search - Tavily DocsSkip to main contentTavily Docs home pageSearch...⌘KSupportGet an API keyGet an API keySearch...NavigationAPI ReferenceTavily SearchHomeDocumentationSDKsExamplesFAQChangelogAPI PlaygroundCommunityBlogOverviewAboutQuickstartCredits & PricingRate LimitsAPI ReferenceIntroductionPOSTTavily SearchPOSTTavily ExtractPOSTTavily CrawlPOSTTavily MapTavily Research (Beta)GETUsageBest PracticesBest Practices for SearchBest Practices for ExtractBest Practices for CrawlAPI Key ManagementTavily MCP ServerTavily MCP ServerStreamingStreamingPartnershipsIBMMarketplacesSnowflakeIntegrationsLangChainVercel AI SDKLlamaIndexOpenAIGoogle ADKAnthropicn8nMakeAgent BuilderLangflowZapierTinesDifyComposioAgnoPydantic AIFlowiseAICrewAIStackAILegalSecurity & CompliancePrivacy PolicyHelpHelp CenterTavily Search CrawlerTavily Search CrawlerPython SDKPythonCopyAsk AIfrom tavily import TavilyClient\\n\\ntavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\")\\nresponse = tavily_client.search(\"Who is Leo Messi?\")\\n\\nprint(response)200400401429432433500CopyAsk AI{\\n  \"query\": \"Who is Leo Messi?\",\\n  \"answer\": \"Lionel Messi, born in 1987, is an Argentine footballer widely regarded as one of the greatest players of his generation. He spent the majority of his career playing for FC Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal-scoring ability. He has won multiple FIFA Ballon d\\'Or awards, numerous La Liga titles with Barcelona, and holds the record for most goals scored in a calendar year. In 2014, he led Argentina to the World Cup final, and in 2015, he helped Barcelona capture another treble. Despite turning 36 in June, Messi remains highly influential in the sport.\",\\n  \"images\": [],\\n  \"results\": [\\n    {\\n      \"title\": \"Lionel Messi Facts | Britannica\",\\n      \"url\": \"https://www.britannica.com/facts/Lionel-Messi\",\\n      \"content\": \"Lionel Messi, an Argentine footballer, is widely regarded as one of the greatest football players of his generation. Born in 1987, Messi spent the majority of his career playing for Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal\",\\n      \"score\": 0.81025416,\\n      \"raw_content\": null,\\n      \"favicon\": \"https://britannica.com/favicon.png\"\\n    }\\n  ],\\n  \"response_time\": \"1.67\",\\n  \"auto_parameters\": {\\n    \"topic\": \"general\",\\n    \"search_depth\": \"basic\"\\n  },\\n  \"usage\": {\\n    \"credits\": 1\\n  },\\n  \"request_id\": \"123e4567-e89b-12d3-a456-426614174111\"\\n}API ReferenceTavily SearchCopy pageExecute a search query using Tavily Search.Copy pagePOST/searchPython SDKPythonCopyAsk AIfrom tavily import TavilyClient\\n\\ntavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\")\\nresponse = tavily_client.search(\"Who is Leo Messi?\"),tavily_client = TavilyClient(api_key=\"tvly-YOUR_API_KEY\")\\nresponse = tavily_client.search(\"Who is Leo Messi?\")\\n\\nprint(response)200400401429432433500CopyAsk AI{\\n  \"query\": \"Who is Leo Messi?\",\\n  \"answer\": \"Lionel Messi, born in 1987, is an Argentine footballer widely regarded as one of the greatest players of his generation. He spent the majority of his career playing for FC Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal-scoring ability. He has won multiple FIFA Ballon d\\'Or awards, numerous La Liga titles with Barcelona, and holds the record for most goals scored in a calendar year. In 2014, he led Argentina to the World Cup final, and in 2015, he helped Barcelona capture another treble. Despite turning 36 in June, Messi remains highly influential in the sport.\",\\n  \"images\": [],\\n  \"results\": [\\n    {\\n      \"title\": \"Lionel Messi Facts | Britannica\",\\n      \"url\": \"https://www.britannica.com/facts/Lionel-Messi\",\\n      \"content\": \"Lionel Messi, an Argentine footballer, is widely regarded as one of the greatest football players of his generation. Born in 1987, Messi spent the majority of his career playing for Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal\",\\n      \"score\": 0.81025416,\\n      \"raw_content\": null,\\n      \"favicon\": \"https://britannica.com/favicon.png\"\\n    }\\n  ],\\n  \"response_time\": \"1.67\",\\n  \"auto_parameters\": {\\n    \"topic\": \"general\",\\n    \"search_depth\": \"basic\"\\n  },\\n  \"usage\": {\\n    \"credits\": 1\\n  },\\n  \"request_id\": \"123e4567-e89b-12d3-a456-426614174111\"\\n}Authorizations\\u200bAuthorizationstringheaderrequiredBearer authentication header in the form Bearer , where  is your Tavily API key (e.g., Bearer tvly-YOUR_API_KEY).Bodyapplication/jsonParameters for the Tavily Search request.\\u200bquerystringrequiredThe search query to execute with Tavily.Example:\"who is Leo Messi?\"\\u200bsearch_depthenum<string>default:basicThe depth of the search:\\n\\nadvanced: Multiple, semantically relevant snippets per URL ( configurable with chunks_per_source )\\nbasic: One generic snippet per URL\\nfast (beta):  Optimized for low latency while maintaining high relevance to the user query\\nultra-fast (beta): Optimized strictly for latency\\n\\nCost:,basic, fast, ultra-fast: 1 API Credit\\nadvanced: 2 API Credits,Available options: advanced, basic, fast, ultra-fast \\u200bchunks_per_sourceintegerdefault:3Chunks are short content snippets (maximum 500 characters each) pulled directly from the source. Use chunks_per_source to define the maximum number of relevant chunks returned per source and to control the content length. Chunks will appear in the content field as: <chunk 1> [...] <chunk 2> [...] <chunk 3>. Available only when search_depth is advanced.Required range: 1 <= x <= 3\\u200bmax_resultsintegerdefault:5The maximum number of search results to return.Required range: 0 <= x <= 20Example:1\\u200btopicenum<string>default:generalThe category of the search.news is useful for retrieving real-time updates, particularly about politics, sports, and major current events covered by mainstream media sources. general is for broader, more general-purpose searches that may include a wide range of sources.Available options: general, news, finance \\u200btime_rangeenum<string>The time range back from the current date to filter results based on publish date or last updated date. Useful when looking for sources that have published or updated data.Available options: day, week, month, year, d, w, m, y \\u200bstart_datestringWill return all results after the specified start date based on publish date or last updated date. Required to be written in the format YYYY-MM-DDExample:\"2025-02-09\"\\u200bend_datestringWill return all results before the specified end date based on publish date or last updated date. Required to be written in the format YYYY-MM-DDExample:\"2025-12-29\"\\u200binclude_answerbooleanenum<string>default:falseInclude an LLM-generated answer to the provided query. basic or true returns a quick answer. advanced returns a more detailed answer.\\u200binclude_raw_contentbooleanenum<string>default:falseInclude the cleaned and parsed HTML content of each search result. markdown or true returns search result content in markdown format. text returns the plain text from the results and may increase latency.\\u200binclude_imagesbooleandefault:falseAlso perform an image search and include the results in the response.\\u200binclude_image_descriptionsbooleandefault:falseWhen include_images is true, also add a descriptive text for each image.\\u200binclude_faviconbooleandefault:falseWhether to include the favicon URL for each result.\\u200binclude_domainsstring[]A list of domains to specifically include in the search results. Maximum 300 domains.\\u200bexclude_domainsstring[]A list of domains to specifically exclude from the search results. Maximum 150 domains.\\u200bcountryenum<string>Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general.Available options: afghanistan, albania, algeria, andorra, angola, argentina, armenia, australia, austria, azerbaijan, bahamas, bahrain, bangladesh, barbados, belarus, belgium, belize, benin, bhutan, bolivia, bosnia and herzegovina, botswana, brazil, brunei, bulgaria, burkina faso, burundi, cambodia, cameroon, canada, cape verde, central african republic, chad, chile, china, colombia, comoros, congo, costa rica, croatia, cuba, cyprus, czech republic, denmark, djibouti, dominican republic, ecuador, egypt, el salvador, equatorial guinea, eritrea, estonia, ethiopia, fiji, finland, france, gabon, gambia, georgia, germany, ghana, greece, guatemala, guinea, haiti, honduras, hungary, iceland, india, indonesia, iran, iraq, ireland, israel, italy, jamaica, japan, jordan, kazakhstan, kenya, kuwait, kyrgyzstan, latvia, lebanon, lesotho, liberia, libya, liechtenstein, lithuania, luxembourg, madagascar, malawi, malaysia, maldives, mali, malta, mauritania, mauritius, mexico, moldova, monaco, mongolia, montenegro, morocco, mozambique, myanmar, namibia, nepal, netherlands, new zealand, nicaragua, niger, nigeria, north korea, north macedonia, norway, oman, pakistan, panama, papua new guinea, paraguay, peru, philippines, poland, portugal, qatar, romania, russia, rwanda, saudi arabia, senegal, serbia, singapore,,korea, north macedonia, norway, oman, pakistan, panama, papua new guinea, paraguay, peru, philippines, poland, portugal, qatar, romania, russia, rwanda, saudi arabia, senegal, serbia, singapore, slovakia, slovenia, somalia, south africa, south korea, south sudan, spain, sri lanka, sudan, sweden, switzerland, syria, taiwan, tajikistan, tanzania, thailand, togo, trinidad and tobago, tunisia, turkey, turkmenistan, uganda, ukraine, united arab emirates, united kingdom, united states, uruguay, uzbekistan, venezuela, vietnam, yemen, zambia, zimbabwe \\u200bauto_parametersbooleandefault:falseWhen auto_parameters is enabled, Tavily automatically configures search parameters based on your query\\'s content and intent. You can still set other parameters manually, and your explicit values will override the automatic ones. The parameters include_answer, include_raw_content, and max_results must always be set manually, as they directly affect response size. Note: search_depth may be automatically set to advanced when it\\'s likely to improve results. This uses 2 API credits per request. To avoid the extra cost, you can explicitly set search_depth to basic.\\u200binclude_usagebooleandefault:falseWhether to include credit usage information in the response.Response200application/jsonSearch results returned successfully\\u200bquerystringrequiredThe search query that was executed.Example:\"Who is Leo Messi?\"\\u200banswerstringrequiredA short answer to the user\\'s query, generated by an LLM. Included in the response only if include_answer is requested (i.e., set to true, basic, or advanced)Example:\"Lionel Messi, born in 1987, is an Argentine footballer widely regarded as one of the greatest players of his generation. He spent the majority of his career playing for FC Barcelona, where he won numerous domestic league titles and UEFA Champions League titles. Messi is known for his exceptional dribbling skills, vision, and goal-scoring ability. He has won multiple FIFA Ballon d\\'Or awards, numerous La Liga titles with Barcelona, and holds the record for most goals scored in a calendar year. In 2014, he led Argentina to the World Cup final, and in 2015, he helped Barcelona capture another treble. Despite turning 36 in June, Messi remains highly influential in the sport.\"\\u200bimagesobject[]requiredList of query-related images. If include_image_descriptions is true, each item will have url and description.Show child attributesExample:[]\\u200bresultsobject[]requiredA list of sorted search results, ranked by relevancy.Show child attributes\\u200bresponse_timenumber<float>requiredTime in seconds it took to complete the request.Example:\"1.67\"\\u200bauto_parametersobjectA dictionary of the selected auto_parameters, only shown when auto_parameters is true.Example:{  \"topic\": \"general\",  \"search_depth\": \"basic\"}\\u200busageobjectCredit usage details for the request.Example:{ \"credits\": 1 }\\u200brequest_idstringA unique request identifier you can share with customer support to help resolve issues with specific requests.Example:\"123e4567-e89b-12d3-a456-426614174111\"IntroductionTavily Extract⌘IxgithublinkedinwebsitePowered by Mintlify'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from pydantic import AnyUrl\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def scraper(url: AnyUrl) -> str:\n",
    "    \"\"\"\n",
    "    Docstring for scraper\n",
    "    \n",
    "    :param url: This function is just made for making a basic web scraping tool\n",
    "    :type url: AnyUrl\n",
    "    :return: The whole content of the website\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    loading = WebBaseLoader(str(url))\n",
    "    loader = loading.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter()\n",
    "    splitted_docs = text_splitter.split_documents(loader)\n",
    "\n",
    "    doc_content = []\n",
    "\n",
    "    for doc in splitted_docs:\n",
    "        doc_content.append(doc.page_content)\n",
    "    \n",
    "    answer = ','.join([doc for doc in doc_content])\n",
    "    answer_string = str(answer)\n",
    "    return answer_string\n",
    "\n",
    "url = \"https://docs.tavily.com/documentation/api-reference/endpoint/search\"\n",
    "answer = scraper(url=url)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced7aa4",
   "metadata": {},
   "source": [
    "## arxiv tool for research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDroid: LLM-powered Task Automation in\n",
      "Android\n",
      "Hao Wen1, Yuanchun Li1,2,†, Guohong Liu1, Shanhui Zhao1,∗, Tao Yu1,∗,\n",
      "Toby Jia-Jun Li3, Shiqi Jiang4, Yunhao Liu5, Yaqin Zhang1, Yunxin Liu1,2\n",
      "1 Institute for AI Industry Research (AIR), Tsinghua University\n",
      "2 Shanghai Artificial Intelligence Laboratory\n",
      "3 Department of Computer Science and Engineering, University of Notre Dame\n",
      "4 Microsoft Research\n",
      "5 Global Innovation Exchange & Department of Automation, Tsinghua University\n",
      "ABSTRACT\n",
      "Mobile task automation is an attractive technique that aims\n",
      "to enable voice-based hands-free user interaction with smart-\n",
      "phones. However, existing approaches suffer from poor scala-\n",
      "bility due to the limited language understanding ability and\n",
      "the non-trivial manual efforts required from developers or end-\n",
      "users. The recent advance of large language models (LLMs)\n",
      "in language understanding and reasoning inspires us to re-\n",
      "think the problem from a model-centric perspective, where\n",
      "task preparation, comprehension, and execution are handled\n",
      "by a unified language model. In this work, we introduce Au-\n",
      "toDroid, a mobile task automation system capable of han-\n",
      "dling arbitrary tasks on any Android application without man-\n",
      "ual efforts. The key insight is to combine the commonsense\n",
      "knowledge of LLMs and domain-specific knowledge of apps\n",
      "through automated dynamic analysis. The main components\n",
      "include a functionality-aware UI representation method that\n",
      "bridges the UI with the LLM, exploration-based memory\n",
      "injection techniques that augment the app-specific domain\n",
      "knowledge of LLM, and a multi-granularity query optimiza-\n",
      "tion module that reduces the cost of model inference. We\n",
      "integrate AutoDroid with off-the-shelf LLMs including on-\n",
      "line GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its\n",
      "performance on a new benchmark for memory-augmented\n",
      "Android task automation with 158 common tasks. The results\n",
      "† Corresponding author: Yuanchun Li (liyuanchun@air.tsinghua.edu.cn).\n",
      "* Shanhui Zhao and Tao Yu were student interns at Tsinghua University.\n",
      "Permission to make digital or hard copies of part or all of this work for\n",
      "personal or classroom use is granted without fee provided that copies are not\n",
      "made or distributed for profit or commercial advantage and that copies bear\n",
      "this notice and the full citation on the first page. Copyrights for third-party\n",
      "components of this work must be honored. For all other uses, contact the\n",
      "owner/author(s).\n",
      "ACM MobiCom ’24, September 30–October 4, 2024, Washington D.C., DC,\n",
      "USA\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-0489-5/24/09.\n",
      "https://doi.org/10.1145/3636534.3649379\n",
      "demonstrated that AutoDroid is able to precisely generate\n",
      "actions with an accuracy of 90.9%, and complete tasks with\n",
      "a success rate of 71.3%, outperforming the GPT-4-powered\n",
      "baselines by 36.4% and 39.7%.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Ubiquitous and mobile\n",
      "computing; • Computing methodologies →Artificial intel-\n",
      "ligence.\n",
      "KEYWORDS\n",
      "Task Automation, Large Language Models, App Analysis\n",
      "ACM Reference Format:\n",
      "Hao Wen1, Yuanchun Li1,2,†, Guohong Liu1, Shanhui Zhao1,∗, Tao\n",
      "Yu1,∗,, Toby Jia-Jun Li3, Shiqi Jiang4, Yunhao Liu5, Yaqin Zhang1,\n",
      "Yunxin Liu1,2. 2024. AutoDroid: LLM-powered Task Automation\n",
      "in Android. In International Conference On Mobile Computing And\n",
      "Networking (ACM MobiCom ’24), September 30–October 4, 2024,\n",
      "Washington D.C., DC, USA. ACM, New York, NY, USA, 15 pages.\n",
      "https://doi.org/10.1145/3636534.3649379\n",
      "1\n",
      "INTRODUCTION\n",
      "Smartphone is one of the most sophisticated devices for indi-\n",
      "viduals. With millions of mobile applications (apps for short)\n",
      "that have access to various embedded sensors and rich per-\n",
      "sonal data, smartphones can be used for a lot of daily tasks\n",
      "such as ordering food, managing social networks, sensing and\n",
      "tracking health conditions, etc. Therefore, how to intelligently\n",
      "automate tasks on smartphones has become an attractive topic\n",
      "for mobile developers and researchers, due to its potential\n",
      "to significantly improve user experience \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "\n",
    "def get_information_about_research_papers(query: str):\n",
    "    retriever = ArxivRetriever(\n",
    "        load_max_docs=1,\n",
    "        get_full_documents=True\n",
    "    )\n",
    "    \n",
    "    documents = retriever.invoke(query)\n",
    "    paper_content = documents[0].page_content\n",
    "    return paper_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9c9a3",
   "metadata": {},
   "source": [
    "now we will build a simple graph structure that has the power to call tools (the arxiv agent and the scraper tool), and it will follow the REact agent architecture. let's see how to build it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a570991",
   "metadata": {},
   "source": [
    "query --> llm --> tool --> output ---> llm --> tool --> output --> llm --> llm_reasoing --> output --> end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfbb52e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is an open-source, Python-based framework for building and deploying large language models (LLMs) in real-world applications. It provides a set of tools and libraries to help developers create, train, and integrate LLMs into their projects.\\n\\nHere are some of the key use cases and features of LangChain:\\n\\n1. **LLM Integration**: LangChain allows developers to integrate LLMs into their applications, enabling features like text generation, sentiment analysis, language translation, and more.\\n2. **Model Training**: LangChain provides tools for training and fine-tuning LLMs, including support for popular models like BERT, RoBERTa, and T5.\\n3. **Model Serving**: LangChain enables developers to deploy and serve LLMs in production environments, making it easy to integrate LLMs into web applications, APIs, and other systems.\\n4. **Conversational AI**: LangChain provides a set of tools for building conversational AI applications, including support for dialogue management, intent detection, and response generation.\\n5. **Text Generation**: LangChain enables developers to generate text using LLMs, which can be used for applications like content generation, chatbots, and more.\\n6. **Knowledge Retrieval**: LangChain provides tools for retrieving knowledge from LLMs, which can be used for applications like question answering, information retrieval, and more.\\n7. **Model Interpretability**: LangChain includes tools for analyzing and interpreting LLMs, which can help developers understand how the models are making predictions.\\n\\nSome potential use cases for LangChain include:\\n\\n1. **Chatbots**: LangChain can be used to build chatbots that can understand and respond to user queries, using LLMs for text generation and intent detection.\\n2. **Content Generation**: LangChain can be used to generate content automatically, such as product descriptions, blog posts, and more.\\n3. **Virtual Assistants**: LangChain can be used to build virtual assistants that can understand and respond to user queries, using LLMs for text generation and intent detection.\\n4. **Language Translation**: LangChain can be used to translate text from one language to another, using LLMs for machine translation.\\n5. **Sentiment Analysis**: LangChain can be used to analyze sentiment in text data, using LLMs for sentiment analysis.\\n\\nOverall, LangChain provides a powerful framework for building and deploying LLMs in real-world applications, and has a wide range of potential use cases across various industries.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", api_key = groq_api_key)\n",
    "\n",
    "result = llm.invoke(\"what is the use of langchain?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be748a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Literal\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    url: Optional[str]\n",
    "    action: Optional[Literal[\"scrape\", \"arxiv\", \"none\"]]\n",
    "    scraped_content: Optional[str]\n",
    "    paper_content: Optional[str]\n",
    "    output: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48985555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def scrape_website(url: str) -> str:\n",
    "    \"\"\"\n",
    "    scrape textual content from a website\n",
    "    \"\"\"\n",
    "    return scraper(url)\n",
    "\n",
    "@tool\n",
    "def search_research_papers(query: str) -> str:\n",
    "    \"\"\"Fetch relevant arXiv paper content\"\"\"\n",
    "    return get_information_about_research_papers(query)\n",
    "\n",
    "\n",
    "def llm_router(state: AgentState) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI router.\n",
    "\n",
    "Decide the best action:\n",
    "- Use `scrape` if the query involves a website or URL\n",
    "- Use `arxiv` if the query is about research papers or academic content\n",
    "- Use  `none` if none of the above\n",
    "\n",
    "Query: {state['query']}\n",
    "URL: {state.get('url')}\n",
    "\n",
    "Respond ONLY with one word: scrape or arxiv \n",
    "\"\"\"\n",
    "    decision = llm.invoke(prompt).content.strip().lower()\n",
    "    return {\n",
    "        \"action\" : decision\n",
    "    }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9301282",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'Synthesize'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m graph.add_edge(\u001b[33m\"\u001b[39m\u001b[33marxiv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSynthesize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m graph.add_edge(\u001b[33m\"\u001b[39m\u001b[33mSynthesize\u001b[39m\u001b[33m\"\u001b[39m, END)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m app = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraph\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:861\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    858\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    860\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    870\u001b[39m output_channels = (\n\u001b[32m    871\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m     ]\n\u001b[32m    879\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LangGraph\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:785\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    788\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    789\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'Synthesize'"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode([scrape_website, search_research_papers])\n",
    "\n",
    "def route_action(state: AgentState):\n",
    "    if state[\"action\"] == \"scrape\":\n",
    "        return \"scrape\"\n",
    "    \n",
    "    if state[\"action\"] == \"arxiv\":\n",
    "        return \"arxiv\"\n",
    "    \n",
    "    if state[\"action\"] == \"none\":\n",
    "        return \"none\"\n",
    "\n",
    "def scraper_adapter(state: AgentState) -> dict:\n",
    "    return {\n",
    "        \"scraped_content\": state[\"messages\"][-1].content\n",
    "    }\n",
    "\n",
    "\n",
    "def arxiv_adapter(state: AgentState) -> dict:\n",
    "    return {\n",
    "        \"paper_content\": state[\"messages\"][-1].content\n",
    "    }\n",
    "\n",
    "def synthesize_node(state: AgentState) -> dict:\n",
    "    parts = []\n",
    "\n",
    "    if state.get(\"scraped_content\"):\n",
    "        parts.append(\"WEB CONTENT:\\n\" + state[\"scraped_content\"][:2000])\n",
    "\n",
    "    if state.get(\"paper_content\"):\n",
    "        parts.append(\"RESEARCH PAPER:\\n\" + state[\"paper_content\"][:2000])\n",
    "\n",
    "    return {\n",
    "        \"output\": \"\\n\\n\".join(parts)\n",
    "    }\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"router\", llm_router)\n",
    "graph.add_node(\"tool_executor\", tool_node)\n",
    "graph.add_node(\"scrape\", scraper_adapter)\n",
    "graph.add_node(\"arxiv\", arxiv_adapter)\n",
    "graph.add_node(\"synthesizer\", synthesize_node)\n",
    "\n",
    "graph.add_edge(START, \"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_action,\n",
    "    {\n",
    "        \"scrape\": \"tool_executor\",\n",
    "        \"arxiv\": \"tool_executor\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tool_executor\", \"scrape\")\n",
    "graph.add_edge(\"tool_executor\", \"arxiv\")\n",
    "\n",
    "graph.add_edge(\"scrape\", \"Synthesize\")\n",
    "graph.add_edge(\"arxiv\", \"Synthesize\")\n",
    "\n",
    "graph.add_edge(\"Synthesize\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
