{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff4241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c37bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Groq is a US-based company that specializes in developing and manufacturing high-performance, low-power artificial intelligence (AI) hardware and software solutions. \\n\\nTheir primary product, the Groq Chip, is a purpose-built AI processing unit (APU) that's designed to accelerate AI workloads such as deep learning and natural language processing. The chip is optimized for low power consumption and high performance, making it suitable for applications in areas like edge AI, data center AI, and AI inference.\\n\\nThe Groq Chip has been praised for its ability to achieve high performance per watt and its low latency, making it an attractive solution for applications that require real-time AI processing.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 40, 'total_tokens': 173, 'completion_time': 0.245977988, 'completion_tokens_details': None, 'prompt_time': 0.001870386, 'prompt_tokens_details': None, 'queue_time': 0.050267403, 'total_time': 0.247848374}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b4080-9282-7f21-bbd5-ad7d25209dc0-0' usage_metadata={'input_tokens': 40, 'output_tokens': 133, 'total_tokens': 173}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", api_key=groq_api_key)\n",
    "\n",
    "query = \"What is groq?\"\n",
    "result = llm.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d8cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tsuper_bot(super_bot)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> super_bot;\n",
      "\tsuper_bot --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def super_bot(state: AgentState):\n",
    "    return {\"messages\":[llm.invoke(state['messages'])]}\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"super_bot\", super_bot)\n",
    "\n",
    "graph.add_edge(START, \"super_bot\")\n",
    "graph.add_edge(\"super_bot\", END)\n",
    "\n",
    "graph_builder = graph.compile()\n",
    "\n",
    "print(graph_builder.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9baf11db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is groq-api?', additional_kwargs={}, response_metadata={}, id='df8a7592-6450-4873-b214-a95d47c81fdf'),\n",
       "  AIMessage(content='Groq-API is a query language and API developed by Groq, a company that specializes in building high-performance computing systems for artificial intelligence and machine learning applications. The Groq-API is designed to provide a flexible and efficient way to run queries on large-scale data sets, particularly those that are used in AI and ML models.\\n\\nThe Groq-API allows users to define queries using a simple, high-level language that can be executed against various data stores, such as databases, data warehouses, or even in-memory data structures. The API is optimized for performance and scalability, making it suitable for applications that require fast and efficient querying of large amounts of data.\\n\\nSome of the key features of the Groq-API include:\\n\\n1. **Simple and expressive query language**: The Groq-API provides a simple and easy-to-use query language that allows users to define complex queries in a concise and readable way.\\n2. **High-performance execution**: The Groq-API is designed to execute queries efficiently and quickly, making it suitable for applications that require fast data retrieval and analysis.\\n3. **Scalability**: The Groq-API is built to scale horizontally, allowing it to handle large amounts of data and high query volumes.\\n4. **Flexibility**: The Groq-API supports a range of data stores and formats, making it suitable for use with various data sources and systems.\\n5. **Extensibility**: The Groq-API provides a modular architecture that allows users to extend and customize the API to meet their specific needs.\\n\\nOverall, the Groq-API is a powerful tool for building high-performance AI and ML applications that require fast and efficient querying of large-scale data sets.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 333, 'prompt_tokens': 41, 'total_tokens': 374, 'completion_time': 0.508119147, 'completion_tokens_details': None, 'prompt_time': 0.00196185, 'prompt_tokens_details': None, 'queue_time': 0.05545196, 'total_time': 0.510080997}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b4090-5fb5-7011-836b-8d3075b1fd1c-0', usage_metadata={'input_tokens': 41, 'output_tokens': 333, 'total_tokens': 374})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.invoke(AgentState({\"messages\":\"What is groq-api?\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
